# Code generated by sqlc. DO NOT EDIT.
# versions:
#   sqlc v1.30.0
import datetime
import enum
import pydantic
from typing import Any, Optional
import uuid


class JobTypeEnum(str, enum.Enum):
    ONE_TIME = "one_time"
    SCHEDULED = "scheduled"
    RECURRING = "recurring"


class LogLevelEnum(str, enum.Enum):
    DEBUG = "DEBUG"
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"


class StatusEnum(str, enum.Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"
    ACTIVE = "active"
    INACTIVE = "inactive"


class AlembicVersion(pydantic.BaseModel):
    version_num: str


class ContentHash(pydantic.BaseModel):
    """Tracks content hash occurrences for duplicate detection"""
    content_hash: str
    first_seen_page_id: Optional[uuid.UUID]
    occurrence_count: int
    last_seen_at: datetime.datetime
    created_at: datetime.datetime


class CrawlJob(pydantic.BaseModel):
    """Stores crawl job definitions and execution state"""
    id: uuid.UUID
    # Reference to website template (nullable for inline config jobs)
    website_id: Optional[uuid.UUID]
    job_type: JobTypeEnum
    seed_url: str
    # Inline configuration for jobs without website template
    inline_config: Optional[Any]
    status: StatusEnum
    priority: int
    scheduled_at: Optional[datetime.datetime]
    started_at: Optional[datetime.datetime]
    completed_at: Optional[datetime.datetime]
    cancelled_at: Optional[datetime.datetime]
    cancelled_by: Optional[str]
    cancellation_reason: Optional[str]
    error_message: Optional[str]
    retry_count: int
    max_retries: int
    metadata: Optional[Any]
    variables: Optional[Any]
    progress: Optional[Any]
    created_at: datetime.datetime
    updated_at: datetime.datetime


class CrawlLog(pydantic.BaseModel):
    """Stores detailed crawl execution logs (partitioned by month)"""
    id: int
    job_id: uuid.UUID
    website_id: uuid.UUID
    step_name: Optional[str]
    log_level: LogLevelEnum
    message: str
    context: Optional[Any]
    trace_id: Optional[uuid.UUID]
    created_at: datetime.datetime


class CrawlLog202508(pydantic.BaseModel):
    id: int
    job_id: uuid.UUID
    website_id: uuid.UUID
    step_name: Optional[str]
    log_level: LogLevelEnum
    message: str
    context: Optional[Any]
    trace_id: Optional[uuid.UUID]
    created_at: datetime.datetime


class CrawlLog202509(pydantic.BaseModel):
    id: int
    job_id: uuid.UUID
    website_id: uuid.UUID
    step_name: Optional[str]
    log_level: LogLevelEnum
    message: str
    context: Optional[Any]
    trace_id: Optional[uuid.UUID]
    created_at: datetime.datetime


class CrawlLog202510(pydantic.BaseModel):
    id: int
    job_id: uuid.UUID
    website_id: uuid.UUID
    step_name: Optional[str]
    log_level: LogLevelEnum
    message: str
    context: Optional[Any]
    trace_id: Optional[uuid.UUID]
    created_at: datetime.datetime


class CrawlLog202511(pydantic.BaseModel):
    id: int
    job_id: uuid.UUID
    website_id: uuid.UUID
    step_name: Optional[str]
    log_level: LogLevelEnum
    message: str
    context: Optional[Any]
    trace_id: Optional[uuid.UUID]
    created_at: datetime.datetime


class CrawlLog202512(pydantic.BaseModel):
    id: int
    job_id: uuid.UUID
    website_id: uuid.UUID
    step_name: Optional[str]
    log_level: LogLevelEnum
    message: str
    context: Optional[Any]
    trace_id: Optional[uuid.UUID]
    created_at: datetime.datetime


class CrawlLog202601(pydantic.BaseModel):
    id: int
    job_id: uuid.UUID
    website_id: uuid.UUID
    step_name: Optional[str]
    log_level: LogLevelEnum
    message: str
    context: Optional[Any]
    trace_id: Optional[uuid.UUID]
    created_at: datetime.datetime


class CrawlLog202602(pydantic.BaseModel):
    id: int
    job_id: uuid.UUID
    website_id: uuid.UUID
    step_name: Optional[str]
    log_level: LogLevelEnum
    message: str
    context: Optional[Any]
    trace_id: Optional[uuid.UUID]
    created_at: datetime.datetime


class CrawledPage(pydantic.BaseModel):
    """Stores crawled page data and content"""
    id: uuid.UUID
    website_id: uuid.UUID
    job_id: uuid.UUID
    url: str
    url_hash: str
    content_hash: str
    title: Optional[str]
    extracted_content: Optional[str]
    metadata: Optional[Any]
    gcs_html_path: Optional[str]
    gcs_documents: Optional[Any]
    is_duplicate: bool
    duplicate_of: Optional[uuid.UUID]
    similarity_score: Optional[int]
    crawled_at: datetime.datetime
    created_at: datetime.datetime


class ScheduledJob(pydantic.BaseModel):
    """Stores scheduled crawl job configurations with cron schedules"""
    id: uuid.UUID
    website_id: uuid.UUID
    # Cron expression defining when the job should run
    cron_schedule: str
    # Next scheduled execution time
    next_run_time: datetime.datetime
    # Most recent execution time
    last_run_time: Optional[datetime.datetime]
    # Flag to pause/resume schedule without deleting
    is_active: bool
    # Job-specific configuration overrides
    job_config: Optional[Any]
    created_at: datetime.datetime
    updated_at: datetime.datetime


class Website(pydantic.BaseModel):
    """Stores website configurations and metadata"""
    id: uuid.UUID
    name: str
    base_url: str
    config: Any
    status: StatusEnum
    created_at: datetime.datetime
    updated_at: datetime.datetime
    created_by: Optional[str]
    # Default cron schedule expression for this website (default: "0 0 1,15 * *" runs on 1st and 15th at midnight, approximately every 2 weeks)
    cron_schedule: Optional[str]
    # Timestamp when website was soft deleted (NULL = active)
    deleted_at: Optional[datetime.datetime]


class WebsiteConfigHistory(pydantic.BaseModel):
    """Stores configuration history for websites to track changes over time"""
    id: uuid.UUID
    website_id: uuid.UUID
    # Version number, incremented with each change (starts at 1)
    version: int
    # Full configuration snapshot at this version
    config: Any
    # User or system that made the change
    changed_by: Optional[str]
    # Optional description of why the change was made
    change_reason: Optional[str]
    created_at: datetime.datetime
